---
title: Augmented Reality
modulverantwortlich: fn
dozierende: fn
modulniveau: master
kuerzel: AR
angebotImWs: true
sprache: wahlweise deutsch oder englisch
zuordnung-zum-curriculum: Medieninformatik Master
kreditpunkte: 6
voraussetzungenNachPruefungsordnung: keine über die Zulassungsvoraussetzungen zum Studium hinausgehenden
empfohleneVoraussetzungen: Visual Computing (Bachelor), Algorithmen und Programmierung 1 und 2 (Bachelor), Mathematik 1 und 2 (Bachelor)
published: true
layout: modulbeschreibung.11ty.js
typ: wpm
parent: WAMO-SP, WAMO
schwerpunkt: EXA
kategorie: schwerpunkt

infourl: https://ilu.th-koeln.de/ilias.php?ref_id=87680&cmd=infoScreen&cmdClass=ilrepositorygui&cmdNode=xp&baseClass=ilRepositoryGUI
studienleistungen:
  Einzelleistung:
    art: Fachvortrag (40%), Projektumsetzung und Dokumentation (60%)
    erstpruefer: fn
    zweitpruefer: hs
    datum: vereinbarung
meta:
  status: rfreview

studiengangkriterien:
  globalcitizenship: 0
  internationalisierung: 0
  interdisziplinaritaet: 0
  transfer: 1

---

## Kurzbeschreibung
Diese Vorlesung gibt eine Einführung in die grundlegenden Konzepte der Erweiterten Realität, mit besonderem Schwerpunkt auf Verfahren zur Bildanalyse die für das Tracking in AR Systemen zum Einsatz kommen.

Dabei werden verschiedenste Aspekte der Bild- und Videoverarbeitung,  wie sie in modernen Bearbeitungstools vorkommen, erarbeitet und selbst implementiert. Es werden Methoden zur Bildaufnahme, Bildverarbeitung und Bildsynthese erarbeitet. Die Teilnehmenden sind in der Lage Augmented Reality Anwendungen zu entwerfen, zu implementieren und zu evaluieren und dadurch eigenständige Beiträge in Forschung und Wirtschaft zu leisten.

## Lehrform/SWS
4 SWS: Vorlesung 2 SWS; Praktikum / Projekt 2 SWS

## Arbeitsaufwand
Gesamtaufwand 180 Stunden, davon

- 36h Vorlesung
- 36h Praktikum / Projekt
- 108h Selbststudium


## Learning Outcomes
(WAS) Die Teilnehmenden können Augmented Reality Anwendungen entwerfen, implementieren und evaluieren

(WOMIT) indem sie
 - Filter- und Segmentierungsverfahren beschreiben und implementieren
 - Bild- und Videooperatoren in ihrer Wirkung vergleichen, kombinieren und sinnvoll einsetzen
 - mathematische Beschreibungen von Bild- und Videooperatoren verstehen
 - Featuredetektoren beschreiben und einsetzen
 - Methoden zur Kamerakalibrierung und zum Tracking anwenden
 - Verfahren zur Verdeckungsberechnung zwischen realen und virtuellen Objekten umsetzen
 - Lösungsansätze für die Herausforderungen des Trackings in großen Umgebungen einordnen und gegenüberstellen
 - Situationsbezogene Visualisierungsmethoden analysieren
 - Visuelle Kohärenz zwischen virtuellen und realen Inhalten herstellen
 - Interaktionsmethoden erstellen und analysieren

(WOZU)
um Augmented Reality später in wissenschaftlichen und industriellen Anwendungsszenarien konzipieren, umsetzen und testen zu können.


## Inhalt
- Filterverfahren: Lineare Filter (Box-, Gauss-, Sinc-), Kantendetektoren (Sobel, Laplace, Canny)
- Feature Detektoren (Harris-Corner Detector, SIFT, SURF, etc.)
- Robustes Feature Matching mittels RANSAC, inkrementelles Tracking
- Kamerakalibrierung (Projektive Geometrie, Kameramodelle) und Tracking Methoden
- Tiefenrekonstruktion und Verdeckung
- Python, C# Programmierung

## Medienformen
- Beamergestützte Vorlesung;
- Praktika / Projekt in Kleingruppen, um die erlernten Methoden und Techniken einzuüben und zu vertiefen (Rechnerlabor)

## Literatur
- Dieter Schmalstieg, Tobias Höllerer, Augmented Reality: Principles and Practice, Addison-Wesley Professional, 2016
- Reinhard Klette, Concise Computer Vision: An introduction into theory and algorithms, Springer, 2014
- Richard Hartley and Andrew Zisserman, Multiple View Geometry in Computer Vision, Cambridge 2000
